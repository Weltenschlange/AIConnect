# To-Do List

## Data Preparation
- [✅] Download ZebraLogicBench dataset from Hugging Face
  - Reference: https://huggingface.co/datasets/allenai/ZebraLogicBench
- [ ] Understand grid_mode.parquet structure (1,000 logic grid puzzles)
- [ ] Understand mc_mode.parquet structure (3,259 multiple-choice questions)
- [✅] Extract puzzles into CSP variables, domains, and constraint lists

## Core Functionality
- [✅] Implement backtracking CSP solver with MRV (Minimum Remaining Values)
- [✅] Implement forward checking for the CSP solver
- [✅] Implement arc consistency algorithm
- [ ] Make the Solver faster
- [✅] Parse natural language clues into CSP format
- [✅] Validate that solutions generated by the solver are actually correct
- [ ] Parse the solution from constraint_solver into the proper JSON or CSV format (we dont know what format they actualy want now)
- [ ] Create trace generator script to log feature vectors at each decision (domain sizes, constraints, chosen variable/value)

## Testing & Evaluation
- [ ] Create evaluation notebook to run solver on validation set
- [ ] Evaluate on validation set
- [ ] Compute metrics:
  - Composite Score = Accuracy (%) – 10 × (AvgSteps / MaxAvgSteps)
- [ ] Final evaluation on held-out test puzzles

## Project Setup
- [ ] Add solver.py and/or notebook.ipynb
- [ ] Add run.py to run solver on test script
- [ ] Add README.md explaining our approach
- [ ] Create data parsing notebook/script
- [ ] Create trace generation notebook/script
- [ ] Figure out how to handle puzzles that could not be parsed correctly

## Report & Documentation
- [ ] Write final report with:
  - Architecture overview
  - Experimental setup
  - Quantitative results (tables, charts)
  - Discussion and insights
- [ ] Create 2-minute video demonstration of solver

## Kaggle Submission
- [ ] Create submission containing:
  - solver.py or notebook.ipynb
  - run.py script to run solver on test puzzles
  - README.md explaining approach
  - results.json with output for test set
- [ ] Figure out how to upload the project to Kaggle
- [ ] Figure out how to get our solution evaluated
  - Reference: www.kaggle.com/competitions/ai-connect-2025/overview/evaluation
















## Kaggle:
www.kaggle.com/competitions/ai-connect-2025/overview/submission